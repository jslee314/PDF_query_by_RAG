import streamlit as st
from langchain.callbacks.tracers import LangChainTracer
from rag.loader import load_and_split
from rag.embedder import get_embeddings, create_vectorstore
from rag.retriever import HybridRetriever
from rag.translator import build_translator_chain

from langchain_core.runnables import RunnablePassthrough
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
import yaml


def create_chain(retriever_fn, model_name="gpt-4o", temperature=0.0, tracer=None):
    with open("prompts/pdf-rag.yaml", encoding="utf-8") as f:
        spec = yaml.safe_load(f)
    prompt = PromptTemplate(
        template=spec["template"],
        input_variables=spec["input_variables"],
    )
    llm = ChatOpenAI(
        model_name=model_name,
        temperature=temperature,
        callbacks=[tracer] if tracer else None
    )
    return (
        {"context": retriever_fn, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )


def render(uploaded_files, selected_model, temperature, translator_chain, tracer):
    st.header("1. ë¬¸ì„œ ì—…ë¡œë“œ ë° ì²˜ë¦¬")

    if not uploaded_files:
        st.info("ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        return

    total = len(uploaded_files)
    progress = st.progress(0)

    split_docs_by_file = {}
    file_retrievers = {}
    file_chains = {}

    for idx, f in enumerate(uploaded_files, start=1):
        st.subheader(f"ğŸ”„ ì²˜ë¦¬ ì¤‘: {f.name}")
        docs = load_and_split([f])
        st.write(f"- ì²­í¬ ìƒì„±: {len(docs)}ê°œ")
        split_docs_by_file[f.name] = docs

        embeddings = get_embeddings()
        st.write("- ì„ë² ë”© ê°ì²´ ìƒì„± ì™„ë£Œ")

        vs = create_vectorstore(docs, embeddings)
        n_vectors = getattr(vs.index, "ntotal", "N/A")
        st.write(f"- ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ: ì´ {n_vectors}ê°œ ë²¡í„°")
        file_retrievers[f.name] = vs.as_retriever()

        chain = create_chain(
            retriever_fn=file_retrievers[f.name],
            model_name=selected_model,
            temperature=temperature,
            tracer=tracer
        )
        st.write("- RAG ì²´ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
        file_chains[f.name] = chain

        progress.progress(int(idx / total * 100))

    progress.empty()
    st.success("âœ… ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ!")

    st.session_state["split_docs_by_file"] = split_docs_by_file
    st.session_state["file_retrievers"] = file_retrievers
    st.session_state["file_chains"] = file_chains
    st.session_state["processed"] = True