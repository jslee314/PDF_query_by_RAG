# qa_processor.py
import streamlit as st
from langchain_core.messages.chat import ChatMessage

def render(*, user_input: str, translator_chain, tracer):
    """
    ì§ˆë¬¸ ì²˜ë¦¬ ë° ë‹µë³€ ë Œë”ë§

    Keyword-only arguments:
    - user_input: ì´ì „ì— ì…ë ¥ëœ ì§ˆë¬¸(í•œê¸€)
    - translator_chain: í•œê¸€ ì§ˆë¬¸ì„ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì²´ì¸
    - tracer: LangChain íŠ¸ë ˆì´ì„œ
    """
    st.header("2. ì§ˆë¬¸ ì…ë ¥ ë° ë‹µë³€")

    # ë¬¸ì„œ ì²˜ë¦¬ ëª¨ë“œê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
    if not st.session_state.get("processed", False):
        st.warning("ë¨¼ì € 'ë¬¸ì„œ ì²˜ë¦¬' ëª¨ë“œì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•˜ì„¸ìš”.")
        return

    # ì§ˆë¬¸ ì…ë ¥
    question = st.text_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”", value=user_input)
    if not question:
        return
    # ì„¸ì…˜ì— ì§ˆë¬¸ ì €ì¥
    st.session_state["last_question"] = question

    # ì˜ì–´ë¡œ ë²ˆì—­
    eng_q = translator_chain.predict(text=question)
    st.write(f"ğŸ”„ ë²ˆì—­ëœ ì§ˆë¬¸: {eng_q}")

    # íŒŒì¼ë³„ ë¦¬íŠ¸ë¦¬ë²„ ìƒìœ„ ê²°ê³¼
    st.subheader("ğŸ“‚ íŒŒì¼ë³„ ìœ ì‚¬ë„ ìƒìœ„ ê²°ê³¼")
    for fname, retriever in st.session_state.get("file_retrievers", {}).items():
        with st.expander(fname):
            top_docs = retriever.get_relevant_documents(eng_q)[:3]
            for i, doc in enumerate(top_docs, start=1):
                source = doc.metadata.get("source", fname)
                page   = doc.metadata.get("page", "N/A")
                st.markdown(f"**ê²°ê³¼ {i}** (ì¶œì²˜: {source}, í˜ì´ì§€: {page})")
                st.write(doc.page_content[:300] + "â€¦")

    # íŒŒì¼ë³„ RAG ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°
    st.subheader("ğŸ“„ íŒŒì¼ë³„ ë‹µë³€")
    for fname, chain in st.session_state.get("file_chains", {}).items():
        st.markdown(f"---\n**{fname}**")
        with st.chat_message("assistant"):
            container = st.empty()
            answer = ""
            for token in chain.stream(eng_q):
                answer += token
                container.markdown(answer)

    # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    st.session_state["messages"].append(ChatMessage(role="user", content=question))
    combined = "\n\n".join(
        f"## {fname}\n{chain.invoke(eng_q)}"
        for fname, chain in st.session_state.get("file_chains", {}).items()
    )
    st.session_state["messages"].append(ChatMessage(role="assistant", content=combined))

    # ì´ì „ ëŒ€í™” ì¶œë ¥
    for msg in st.session_state.get("messages", []):
        st.chat_message(msg.role).write(msg.content)
